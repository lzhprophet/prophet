input {
  kafka {
    tags => ["demo"]  
    group_id => "prophet-hdfs"                         #消费者组
    client_id => "prophet-hdfs"
    bootstrap_servers => "172.16.101.213:9092,172.16.101.214:9092"  #kafka的集群地址
    topics => ["prophet-demo-topic"]   #topic     
    codec => "json"
  }

}
 
output {            
#如果你一个topic中会有好几种日志，可以提取出来分开存储在hdfs上。
if  "demo" in [tags] {
    webhdfs {
       host => "172.16.102.74"        #hdfs的namenode地址    
       port => 50070                  #webhdfs端口
       user => "lvzhonghou"           #hdfs运行的用户啊，以这个用户的权限去写hdfs。
       path => "/prophet/demo/%{+YYYY}-%{+MM}-%{+dd}.log"           #按天建目录，按天建log文件。     
	   codec => "json"
	   flush_size => 1000
       	   idle_flush_time => 10
           retry_interval => 0.5
       }
   }
 
  stdout { 
	#codec => json
 	codec => rubydebug
  }
}
